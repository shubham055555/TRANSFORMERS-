# TRANSFORMERS-

Research paper jaroor padhio 
1. Transformer Overview
2. Self Attention
3. Scaled Dot Product Attention
4. Geometric Intuition
5. Multihead Transformer
6. Positional Encoding
7. Layer Normalization in Tranformers
8. Transformer Architecture
9. Masked Self Attention
10. Cross Attention in Transformer
11. Transformer Decoder Architecture
12. Transformer inference 
